# Syracuse Fine-tuning Configuration (Aligned with Baseline Task Definition)

# Data Paths
meta_excel: /data/Nbi/Syracuse/syracuse_original_videos/meta_with_outcomes.xlsx
video_root: /data/Nbi/Syracuse/syracuse_cropped_frames
# Note: Video filename in meta is "IMG_XXXX.MP4", folder is "IMG_XXXX"

# Column Mapping
video_col: file_name
label_col: pain_level
subject_col: subject_id

# Task Definition (Ordinal Regression via Classification)
task: classification
# num_classes: 3
# # Binning cutoffs for 0-10 VAS score -> 5 classes
# cutoffs:  [2.1,5.1]
# Exclude specific videos (based on baseline config)
num_classes: 4
cutoffs: [1.1,3.1,6.1]
# num_classes: 5
# cutoffs: [1.1,3.1,5.1,7.1]
exclude_video_ids:
  - IMG_0006
  - IMG_0008
  - IMG_0009
  - IMG_0015
  - IMG_0036
  - IMG_0040
  - IMG_0057
  - IMG_0098
  - IMG_0108

# Model
embed_dim: 384  # Must match the pretrained TNT-Small dimension

# Fine-tuning strategy (mitigate overfitting on small Syracuse)
# - freeze_mode: "none" | "head" | "temporal" | "spatial"
#   - "head": train head only (freeze spatial + temporal)
#   - "temporal": train temporal + head (freeze spatial)
#   - "spatial": train spatial + head (freeze temporal) [rare; usually not recommended]
freeze_mode: head

# Output (baseline-aligned storage)
# All per-fold/per-subject and global summary files will be written under this directory.
save_dir: /data/Nbi/Marlin/MARLIN/logs_syracuse_finetune/tnt_baseline_no_aux_4class
# If false, do not write any CSV artifacts (training still runs).
save_preds: true

# Augmentation (Swap Face)
aug_video_root: /data/Nbi/Syracuse/syracuse_aug_cropped_frames/aug_videos2
use_aug: false
aug_ratio: 0.75  # Probability to swap to an augmented view during training

# Clip-level protocol (align with baseline)
# We slice each video into many clips via a sliding window over frames.
# Each clip inherits the video label; we predict at clip-level and majority-vote to video-level.
clip_level: true
# ~5s window if fps~30 -> 150 frames. Adjust if needed.
clip_len_frames: 150
# ~0.5s stride if fps~30 -> 15 frames (matches typical window feature extraction density).
clip_stride_frames: 15

# Training Hyperparameters
batch_size: 64
accumulate_grad_batches: 1
num_workers: 8
max_epochs: 50
learning_rate: 1.0e-4
weight_decay: 0.05
smoothing: 0.1

# Early Stopping
patience: 15

# Hardware
gpus: 1
precision: 16

# Validation Strategy
loso: true
# Optional: Limit subjects for debugging (e.g., set to 3 to run only first 3 folds)
# limit_subjects: 3 
