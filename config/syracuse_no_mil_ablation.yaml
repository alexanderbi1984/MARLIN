model_name: syracuse_instance_no_mil_ablation

# Data
syracuse_feature_root: /data/Nbi/Syracuse/syracuse_marlin_rgb_features
syracuse_feature_suffix: _aligned_windows.npy
meta_excel_path: /data/Nbi/Syracuse/meta_with_outcomes.xlsx
baseline_combo: RGB
combos: [RGB]

# === Ablation Settings ===
# Treat each clip as an independent instance (Simple Aggregation over same window)
clip_level: true
clip_bag_size: 5        # Keep same context size as MIL model (5x16 = 80 frames)
clip_bag_stride: 1
exclude_video_ids:
  - IMG_0006
  - IMG_0008
  - IMG_0009
  - IMG_0015
  - IMG_0036
  - IMG_0040
  - IMG_0057
  - IMG_0098
  - IMG_0108
# Aggregator
attn_type: mean         # Use simple Mean Pooling over the 5 tokens instead of Transformer/Attention
# This tests if the *intelligent* aggregation (MIL) matters, or if just averaging features over 80 frames is enough.
# =========================

embed_dim: 256
xformer_dropout: 0.3    # Applies to the projection dropout in MeanPoolAggregator

# Auxiliary Task (Biovid)
# Validates if multitask helps even in instance-level training
biovid_aux_loss_weight: 0.001
aux_meta_excel: /data/Nbi/biovid/biovid_pain_labels.csv
aux_feature_root: /data/Nbi/biovid/MMA_RGB_features_new
use_aug_in_train: true
train_aug_ratio: 1   # probability to sample an aug view if available
aux_feature_suffix: _windows.npy
aux_train_split: train
aux_val_split: val
aux_test_split: test

# Training
task: ordinal          # ordinal | regression | binary | multiclass
num_classes: 5
pain_class_cutoffs: [1.1,3.1,5.1,7.1]

batch_size: 64         # Increased batch size since instances are smaller than bags
num_workers: 8
val_split_ratio: 0.15
test_split_ratio: 0.15
random_state: 42
normalize_features: true
max_bag_size: 800

# Class balancing
use_weighted_sampler: true
train_epoch_multiplier: 1   # >=1; multiply train samples per epoch to increase steps

# Enumerate all combos and K aug views per epoch (train only)
train_enumerate_all_views: false
train_max_aug_per_combo: 4
train_include_original: true

# Loss/Optimization
learning_rate: 5e-5
weight_decay: 0.01
coral_alpha: 0.5
ce_weight: 1.0        # set 0 to disable CE head
class_weights: true    # if true, compute from train labels and pass to CE head

# Trainer
max_epochs: 200
monitor_metric: val_acc
patience: 15
precision: 32

# Device
accelerator: gpu   # 'gpu' | 'cpu' | 'auto'
devices: 1         # number of GPUs to use

# Output
save_dir: Syracuse/ablation_no_mil_clip_level/marlin_features/5class_1_aug_ratio_no_exclude
save_preds: true

# Strategy
loocv: true             # Still use LOOCV for fair comparison with MIL results

