# New hyperparameters for coral_loss
label_smoothing: 0.0  # Default to 0.0 for no label smoothing
use_distance_penalty: false  # Default to false to disable distance penalty
focal_gamma: null  # Default to null to disable focal weighting

# Early stopping configuration
patience: 200  # Early stopping patience (epochs)

# Existing configuration keys
model_name: multitask_pain_stimulus_run_01  # Name for checkpoints and logs
num_pain_classes: 5  # Number of ordinal pain levels (Syracuse)
num_stimulus_classes: 5  # Number of ordinal stimulus levels (BioVid)
syracuse_feature_dir: marlin_vit_small_patch16_224 # Example: Feature directory for Syracuse
biovid_feature_dir: marlin_vit_small_patch16_224   # Example: Feature directory for BioVid (can be the same or different)
shoulder_pain_feature_dir: null  # Optional: feature directory for ShoulderPain dataset, set to null to disable
temporal_reduction: mean  # How to aggregate features temporally (mean, max, min, none)
learning_rate: 1e-4      # Learning rate for the optimizer
weight_decay: 0.0        # Weight decay for optimizer
use_class_weights: false
balance_pain_classes: false
pain_loss_weight: 1.0
stim_loss_weight: 1.0
balance_sources: false
balance_stimulus_classes: false
encoder_hidden_dims: [512, 256] # Example: [hidden1_size, hidden2_size]
use_stim_weight_scheduler: false  # Whether to schedule stimulus loss weight
initial_stim_weight: 5.0          # Initial weight (higher focuses on stimulus task early)
final_stim_weight: 1.0            # Final weight after decay
stim_weight_decay_epochs: 50      # Number of epochs over which to decay the weight
stim_weight_sched_type: "cosine"  # Scheduling type ("cosine" or "linear")

# --- Optional: Fine-tuning from Pretrained Model ---
# Note: These settings are not used directly from this config file.
# Instead, they are provided via command line arguments:
#  --pretrained_checkpoint: Path to the pretrained model checkpoint
#  --freeze_stimulus_head: Flag to freeze the stimulus head during fine-tuning
#  --encoder_lr_factor: Learning rate factor for the encoder (default: 0.1)
#
# Example command for pretraining:
#   python pretrain_biovid.py --config configs/your_config.yaml --biovid_data_path /path/to/biovid
#
# Example command for fine-tuning:
#   python evaluate_multitask.py --config configs/your_config.yaml \
#       --syracuse_data_path /path/to/syracuse \
#       --biovid_data_path /path/to/biovid \
#       --pretrained_checkpoint ckpt/your_model_pretrain/your_model_pretrain-last.ckpt \
#       --freeze_stimulus_head \
#       --encoder_lr_factor 0.1 